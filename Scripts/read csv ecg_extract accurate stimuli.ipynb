{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: PostQuestion_14_10_20230810T095845.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:58:45.921000 and 2023-08-10 09:59:15.897000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_10.csv.\n",
      "\n",
      "File: PostQuestion_14_11_20230810T092531.txt\n",
      "Filtered data between 2023-08-10 09:25:31.237000 and 2023-08-10 09:26:01.213000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_11.csv.\n",
      "\n",
      "File: PostQuestion_14_12_20230810T092741.txt\n",
      "Filtered data between 2023-08-10 09:27:41.510000 and 2023-08-10 09:28:11.486000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_12.csv.\n",
      "\n",
      "File: PostQuestion_14_13_20230810T095723.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:57:23.670000 and 2023-08-10 09:57:53.645000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_13.csv.\n",
      "\n",
      "File: PostQuestion_14_14_20230810T092857.txt\n",
      "Filtered data between 2023-08-10 09:28:57.853000 and 2023-08-10 09:29:27.829000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_14.csv.\n",
      "\n",
      "File: PostQuestion_14_15_20230810T095007.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:50:07.848000 and 2023-08-10 09:50:37.821000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_15.csv.\n",
      "\n",
      "File: PostQuestion_14_16_20230810T092235.txt\n",
      "Filtered data between 2023-08-10 09:22:35.872000 and 2023-08-10 09:23:05.848000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_16.csv.\n",
      "\n",
      "File: PostQuestion_14_17_20230810T095927.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:59:27.124000 and 2023-08-10 09:59:57.100000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_17.csv.\n",
      "\n",
      "File: PostQuestion_14_18_20230810T092037.txt\n",
      "Filtered data between 2023-08-10 09:20:37.592000 and 2023-08-10 09:21:07.569000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_18.csv.\n",
      "\n",
      "File: PostQuestion_14_19_20230810T093139.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:31:39.980000 and 2023-08-10 09:32:09.956000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_19.csv.\n",
      "\n",
      "File: PostQuestion_14_1_20230810T092700.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:27:00.973000 and 2023-08-10 09:27:31.161000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_1.csv.\n",
      "\n",
      "File: PostQuestion_14_20_20230810T100138.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 10:01:38.209000 and 2023-08-10 10:02:08.185000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_20.csv.\n",
      "\n",
      "File: PostQuestion_14_21_20230810T095246.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:52:46.440000 and 2023-08-10 09:53:16.416000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_21.csv.\n",
      "\n",
      "File: PostQuestion_14_22_20230810T092820.txt\n",
      "Filtered data between 2023-08-10 09:28:20.227000 and 2023-08-10 09:28:50.202000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_22.csv.\n",
      "\n",
      "File: PostQuestion_14_23_20230810T093021.txt\n",
      "Filtered data between 2023-08-10 09:30:21.327000 and 2023-08-10 09:30:51.302000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_23.csv.\n",
      "\n",
      "File: PostQuestion_14_24_20230810T100100.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 10:01:00.926000 and 2023-08-10 10:01:30.902000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_24.csv.\n",
      "\n",
      "File: PostQuestion_14_25_20230810T092324.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:23:24.506000 and 2023-08-10 09:23:53.481000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_25.csv.\n",
      "\n",
      "File: PostQuestion_14_26_20230810T093101.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:31:01.975000 and 2023-08-10 09:31:30.951000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_26.csv.\n",
      "\n",
      "File: PostQuestion_14_27_20230810T092158.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:21:58.666000 and 2023-08-10 09:22:27.643000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_27.csv.\n",
      "\n",
      "File: PostQuestion_14_28_20230810T092937.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:29:37.525000 and 2023-08-10 09:30:06.501000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_28.csv.\n",
      "\n",
      "File: PostQuestion_14_29_20230810T095047.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:50:47.126000 and 2023-08-10 09:51:16.102000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_29.csv.\n",
      "\n",
      "File: PostQuestion_14_2_20230810T092449.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:24:49.667000 and 2023-08-10 09:25:19.853000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_2.csv.\n",
      "\n",
      "File: PostQuestion_14_30_20230810T095528.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:55:28.867000 and 2023-08-10 09:55:57.843000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_30.csv.\n",
      "\n",
      "File: PostQuestion_14_31_20230810T091948.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:19:48.381000 and 2023-08-10 09:20:17.359000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_31.csv.\n",
      "\n",
      "File: PostQuestion_14_32_20230810T093300.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:33:00.888000 and 2023-08-10 09:33:29.864000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_32.csv.\n",
      "\n",
      "File: PostQuestion_14_33_20230810T100003.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 10:00:03.796000 and 2023-08-10 10:00:33.773000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_33.csv.\n",
      "\n",
      "File: PostQuestion_14_34_20230810T095122.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:51:22.611000 and 2023-08-10 09:51:52.587000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_34.csv.\n",
      "\n",
      "File: PostQuestion_14_35_20230810T092612.txt\n",
      "Filtered data between 2023-08-10 09:26:12.796000 and 2023-08-10 09:26:42.771000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_35.csv.\n",
      "\n",
      "File: PostQuestion_14_36_20230810T095404.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:54:04.537000 and 2023-08-10 09:54:34.513000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_36.csv.\n",
      "\n",
      "File: PostQuestion_14_37_20230810T095447.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:54:47.273000 and 2023-08-10 09:55:17.250000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_37.csv.\n",
      "\n",
      "File: PostQuestion_14_38_20230810T095646.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:56:46.087000 and 2023-08-10 09:57:16.062000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_38.csv.\n",
      "\n",
      "File: PostQuestion_14_39_20230810T095605.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:56:05.983000 and 2023-08-10 09:56:35.949000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_39.csv.\n",
      "\n",
      "File: PostQuestion_14_3_20230810T092411.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:24:11.140000 and 2023-08-10 09:24:41.327000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_3.csv.\n",
      "\n",
      "File: PostQuestion_14_40_20230810T100302.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 10:03:02.615000 and 2023-08-10 10:03:32.592000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_40.csv.\n",
      "\n",
      "File: PostQuestion_14_4_20230810T093219.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:32:19.484000 and 2023-08-10 09:32:49.671000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_4.csv.\n",
      "\n",
      "File: PostQuestion_14_5_20230810T095323.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:53:23.789000 and 2023-08-10 09:53:53.976000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_5.csv.\n",
      "\n",
      "File: PostQuestion_14_6_20230810T095804.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:58:04.863000 and 2023-08-10 09:58:35.048000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_6.csv.\n",
      "\n",
      "File: PostQuestion_14_7_20230810T100219.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 10:02:19.791000 and 2023-08-10 10:02:49.977000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_7.csv.\n",
      "\n",
      "File: PostQuestion_14_8_20230810T092117.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:21:17.686000 and 2023-08-10 09:21:47.871000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_8.csv.\n",
      "\n",
      "File: PostQuestion_14_9_20230810T095205.txt\n",
      "Required number of samples (3899) has been reached.\n",
      "Filtered data between 2023-08-10 09:52:05.391000 and 2023-08-10 09:52:35.367000 written to C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P14_9.csv.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "file_path = 'C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/P14_ECG_S1.csv'  # Replace with your file path\n",
    "timestamp_format = '%Y/%m/%d %H:%M:%S.%f'\n",
    "            \n",
    "with open(file_path, 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')  # Assuming tab-separated values\n",
    "    headers = next(csv_reader)  # Read the headers\n",
    "    #second_row_headers = next(csv_reader)  # Read the second row of headers\n",
    "    \n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        timestamp_str = row[1]  # Assuming timestamp is in the first column\n",
    "        #timestamp_str1= timestamp_str.split(',')[1] \n",
    "        timestamp = datetime.datetime.strptime(timestamp_str, timestamp_format)\n",
    "        row[1] = timestamp\n",
    "        data.append(row)\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# Function to find the nearest timestamp in the CSV file\n",
    "def find_nearest_timestamp(data1, target_timestamp):\n",
    "    nearest_timestamp = None\n",
    "    min_difference = float('inf')\n",
    "\n",
    "    for row in data1:\n",
    "            # Assuming the timestamp is in the first column of each row\n",
    "            #csv_timestamp = datetime.datetime.strptime(row[1], '%Y-%m-%d %H:%M:%S.%f')  # Adjust the datetime format as per your CSV\n",
    "            csv_timestamp = row[1]\n",
    "            # Calculate the difference in timestamps\n",
    "            difference = abs((csv_timestamp - target_timestamp).total_seconds())  # Get the absolute difference in seconds\n",
    "\n",
    "            if difference < min_difference:\n",
    "                min_difference = difference\n",
    "                nearest_timestamp = csv_timestamp\n",
    "                index = row\n",
    "    return nearest_timestamp, index\n",
    "            \n",
    "directory = 'C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for file_name in files:\n",
    "    if file_name.endswith('.txt') and file_name.startswith('PostQuestion_'):\n",
    "        # Split the filename by underscores and remove the file extension\n",
    "        file_parts = file_name.replace('.txt', '').split('_')\n",
    "\n",
    "        # Extract the timestamp and other details\n",
    "        participant_id = file_parts[1]\n",
    "        video_id = file_parts[2]\n",
    "        date_time= file_parts[3]  # Includes the date and time together\n",
    "\n",
    "        # Extract the date and time from the timestamp\n",
    "        year = date_time[:4]\n",
    "        month = date_time[4:6]\n",
    "        date = date_time[6:8]\n",
    "        hour = date_time[9:11]  # Removing 'T' from the timestamp\n",
    "        minute = date_time[11:13]\n",
    "        second = date_time[13:15]\n",
    "        # Create the full file path\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "\n",
    "        # Open and read the file contents\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            # Process the content as needed\n",
    "            # Example: Print the content of the file along with the extracted details\n",
    "            print(f\"\\nFile: {file_name}\")\n",
    "            \n",
    "            # Splitting the content by newline character to get individual lines\n",
    "            lines = content.split('\\n')\n",
    "\n",
    "            # Initializing lists to store StartTime and StopTime data\n",
    "            start_times = []\n",
    "            stop_times = []\n",
    "\n",
    "            # Processing each line\n",
    "            for line in lines:\n",
    "            # Splitting each line by semicolon to extract individual values\n",
    "                values = line.split(';')\n",
    "    \n",
    "                # Check if the line contains StartTime or StopTime data\n",
    "                if len(values) > 1:\n",
    "                    if values[1].startswith(\"StartTime\"):\n",
    "                        start_times.append(values[1].split(': ')[1])\n",
    "                    elif values[1].startswith(\"StopTime\"):\n",
    "                        stop_times.append(values[1].split(': ')[1])\n",
    "           \n",
    "            # Convert start_times to datetime objects and append the hour\n",
    "            for start_time in start_times:\n",
    "                # Splitting the time components\n",
    "                parts = start_time.split(':')\n",
    "                # Extracting hour, minute, second, and millisecond\n",
    "                minute1 = int(parts[0])\n",
    "                second1 = int(parts[1])\n",
    "                millisecond = int(parts[2])\n",
    "    \n",
    "                # Convert milliseconds to microseconds (1 millisecond = 1000 microseconds)\n",
    "                microsecond = millisecond * 1000\n",
    "                # Creating a datetime object by adding the hour, minute, second, and microsecond\n",
    "                start_timestamp = datetime.datetime(int(year), int(month), int(date), int(hour), minute1, second1, microsecond)\n",
    "                start_timestamp_without_ms = start_timestamp.replace(microsecond=0)\n",
    "            #print('Start Timestamp:', start_timestamp)\n",
    "\n",
    "           \n",
    "            # Convert stop_times to datetime objects and append the hour\n",
    "            for stop_time in stop_times:\n",
    "                # Splitting the time components\n",
    "                parts = stop_time.split(':')\n",
    "                # Extracting hour, minute, second, and millisecond\n",
    "                stop_minute = int(parts[0])\n",
    "                if minute1 == 59 and stop_minute == 0:\n",
    "                    stop_hour = int(hour)+1\n",
    "                else:\n",
    "                    stop_hour = int(hour)\n",
    "                second2 = int(parts[1])\n",
    "                millisecond2 = int(parts[2])\n",
    "                    \n",
    "                # Convert milliseconds to microseconds (1 millisecond = 1000 microseconds)\n",
    "                microsecond2 = millisecond2 * 1000\n",
    "                # Creating a datetime object by adding the hour, minute, second, and microsecond\n",
    "                stop_timestamp = datetime.datetime(int(year), int(month), int(date), stop_hour, stop_minute, second2, microsecond2)\n",
    "                stop_timestamp_without_ms = stop_timestamp.replace(microsecond=0)\n",
    "            #print('Stop Timestamp:', stop_timestamp)\n",
    "            \n",
    "        # Find the nearest timestamps to start and stop times in the CSV file\n",
    "        nearest_start_timestamp, start_index = find_nearest_timestamp(data, start_timestamp)\n",
    "        nearest_stop_timestamp, stop_index = find_nearest_timestamp(data, stop_timestamp)\n",
    "\n",
    "        #print(f\"The nearest start timestamp in the CSV file is: {nearest_start_timestamp}\")\n",
    "        #print(f\"The nearest stop timestamp in the CSV file is: {nearest_stop_timestamp}\")\n",
    "        #print(f\"The index of nearest stop timestamp in the CSV file is: {stop_index}\")\n",
    "        \n",
    "        # Initialize a list to store data between start and stop times\n",
    "        filtered_data = []\n",
    "\n",
    "        # Create the filename\n",
    "        filename = f\"C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P14/RCQoEA data/ecg_P{participant_id}_{video_id}.csv\"\n",
    "              \n",
    "        # Associate each data point with its corresponding timestamp\n",
    "        for entry in data: # Get the timestamp from data\n",
    "            data_timestamp = entry[1]\n",
    "            data_value = entry[2].strip('[]')\n",
    "            # Remove milliseconds from the data timestamp\n",
    "            #data_timestamp_without_ms = data_timestamp.replace(microsecond=0)\n",
    "            \n",
    "            # Check if the timestamp is between the nearest start and stop timestamps\n",
    "            if nearest_start_timestamp <= data_timestamp <= nearest_stop_timestamp:\n",
    "                filtered_data.append([data_timestamp, data_value])\n",
    "\n",
    "            #if start_timestamp_without_ms <= data_timestamp_without_ms  <= stop_timestamp_without_ms:\n",
    "                #print(\"Data timestamp matches the stop timestamp (without milliseconds).\")\n",
    "            \n",
    "        # Check if we have collected 3899 samples and add an extra sample to reach 3900\n",
    "        if len(filtered_data) == 3899:\n",
    "               \n",
    "            # Check if the stop timestamp exists in the filtered data and add an extra sample if possible\n",
    "            if stop_index != -1:\n",
    "                # Get the next sample after the stop timestamp if available\n",
    "                extra_sample = data[data.index(stop_index)+1]\n",
    "                #print(f\"Extra sample after the nearest stop timestamp: {extra_sample}\")\n",
    "                filtered_data.append([extra_sample[1],extra_sample[2].strip('[]')])  # Append the extra sample to reach 3900 samples\n",
    "                \n",
    "            else:\n",
    "                print(\"Nearest stop timestamp not found in the filtered data.\")\n",
    "        else:\n",
    "            print(\"Required number of samples (3899) has been reached.\")\n",
    "   \n",
    "\n",
    "        # Write the filtered data to a CSV file\n",
    "        \n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(headers[1:])  # Write header\n",
    "            csv_writer.writerows(filtered_data)\n",
    "\n",
    "        print(f\"Filtered data between {start_timestamp} and {stop_timestamp} written to {filename}.\")                \n",
    "        \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-76.0'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_sample = data[data.index(stop_index)+1]\n",
    "extra_sample[1]\n",
    "extra_sample[2].strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data:\n",
      "[datetime.datetime(2023, 12, 13, 12, 37, 19, 161677), '2023/12/13 11:35:32.007689', '[-58.0]']\n",
      "[datetime.datetime(2023, 12, 13, 12, 37, 19, 161677), '2023/12/13 11:35:32.015377', '[-62.0]']\n",
      "[datetime.datetime(2023, 12, 13, 12, 37, 19, 161677), '2023/12/13 11:35:32.023066', '[-53.0]']\n",
      "[datetime.datetime(2023, 12, 13, 12, 37, 19, 161677), '2023/12/13 11:35:32.030754', '[-31.0]']\n",
      "[datetime.datetime(2023, 12, 13, 12, 37, 19, 161677), '2023/12/13 11:35:32.038443', '[-33.0]']\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/Sowmya/QOE_CWI/Selected_PID_data/P47/P47_ECG.csv'  # Replace with your file path\n",
    "timestamp_format = '%Y/%m/%d %H:%M:%S.%f'\n",
    "            \n",
    "with open(file_path, 'r') as file:\n",
    "    csv_reader = csv.reader(file, delimiter=',')  # Assuming tab-separated values\n",
    "    headers = next(csv_reader)  # Read the headers\n",
    "    second_row_headers = next(csv_reader)  # Read the second row of headers\n",
    "    \n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        timestamp_str = row[0]  # Assuming timestamp is in the first column\n",
    "        #timestamp_str1= timestamp_str.split(',')[1] \n",
    "        timestamp = datetime.datetime.strptime(timestamp_str, timestamp_format)\n",
    "        row[0] = timestamp\n",
    "        data.append(row)\n",
    "            \n",
    "print(\"\\nData:\")\n",
    "for row in data[:5]:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
